---
title: Projects
nav:
  order: 1
  tooltip: Projects
---

# <i class="fas fa-microscope"></i>Projects
We have ongoing and completed projects from diverse areas. Students from Bogazici University Cognitive Science MS program and Education Technology programs conduct experiments with participants. Students from the Computer Science Department work on creating various virtual environments for these purposes or machine learning applications.

{% include search-info.html %}

{% include section.html %}

## Ongoing Projects

{% capture text %}
This project investigates how affordance perception may affect perceived interval durations during motor action, contributing to the nascent research linking affordances to the interval timing.In this study, we utilize two avatar hand types: normal and pill-shaped (fingerless). We are investigating whether the perceived time passed during motor action (reaching for a pan) differs depending on the hand type (normal, allowing for pan-handle grasping affordance; capsule, no grasping ability afforded) in our participants. LeapMotion hand tracker used with HTC Vive headset. 

{%
  include link.html
  link="research"
  flip=true
%}
{:.center}
{% endcapture %}



{% capture text %}
This project provides an artic sea environment where the player navigates a boat around. The surroundings are icebergs that melt, glaciers and some animated animals present in the exploratory environment. The player can interact with the virtual environment by driving the boat and picking up some objects floating. The project is designed to be used complementary with "This is Climate Change: Melting Ice" 360Â° VR documentary where Former Vice President Al Gore takes viewers on a transcendent exploration into the devastating consequences of our changing climate.
{%
  include link.html
  flip=true
  [Igor Lirussi](http://buviar.boun.edu.tr/members/lirussi-igor.html/) \
[Project's Github Page](https://github.com/igor-lirussi/VR-Boat/)

  
%}
{:.center}
{% endcapture %}

{%
  include feature.html
  image="images/project-boat.jpg"
  link="research"
  title="Glacier Boat"
  text=text
%}





{%
  include feature.html
  image="images/project-sunny.PNG"
  title="The effect of affordances on perceived action durations"
  text=text
%}


{% capture text %}
Research aims to examine how contextual cues affect audiovisual integration processes when determining saliency. Various 360 panoramic videos with ambisonic audio are used with HTC Vive VR headset and eye tracking data is analyzed for different types of videos. Variables include sound type (human, animal, nature, vehicle, music) and scene type (indoors, outdoors-natural, outdoors-human-made).
{%
  include link.html
  flip=true
%}
{:.center}
{% endcapture %}

{%
  include feature.html
  image="images/project-halit.jpg"
  link="research"
  title="Audiovisual Saliency Cues in VR"
  text=text
%}

