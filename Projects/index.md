---
title: Projects
nav:
  order: 6
  tooltip: Projects
---

# <i class="fas fa-microscope"></i>Projects
The lab has several ongoing projects.

{% include search-info.html %}

{% include section.html %}

## Ongoing Projects

{% capture text %}
This project investigates how affordance perception may affect perceived interval durations during motor action, contributing to the nascent research linking affordances to the interval timing.In this study, we utilize two avatar hand types: normal and pill-shaped (fingerless). We are investigating whether the perceived time passed during motor action (reaching for a pan) differs depending on the hand type (normal, allowing for pan-handle grasping affordance; capsule, no grasping ability afforded) in our participants. LeapMotion hand tracker used with HTC Vive headset. 

{%
  include link.html
  link="research"
  text="See our projects"
  icon="fas fa-arrow-right"
  flip=true
%}
{:.center}
{% endcapture %}

{%
  include feature.html
  image="images/buviar_projects.PNG"
  link="research"
  title="The effect of affordances on perceived action durations"
  text=text
%}


{% capture text %}
Research aims to examine how contextual cues affect audiovisual integration processes when determining saliency. Various 360 panoramic videos with ambisonic audio are used with HTC Vive VR headset and eye tracking data is analyzed for different types of videos. Variables include sound type (human, animal, nature, vehicle, music) and scene type (indoors, outdoors-natural, outdoors-human-made).
{%
  include link.html
  link="research"
  text="See our projects"
  icon="fas fa-arrow-right"
  flip=true
%}
{:.center}
{% endcapture %}

{%
  include feature.html
  image="images/buviar_projects.PNG"
  link="research"
  title="Audiovisual Saliency Cues in VR"
  text=text
%}

